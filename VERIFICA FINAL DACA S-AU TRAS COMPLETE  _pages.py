import os
import re
import json
from collections import defaultdict

def load_state_json(json_path):
    """ÃncarcÄƒ fiÈ™ierul state.json"""
    if not os.path.exists(json_path):
        print(f"âŒ FiÈ™ierul {json_path} nu existÄƒ!")
        return []

    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

            if isinstance(data, list):
                return data
            elif isinstance(data, dict):
                for value in data.values():
                    if isinstance(value, list):
                        return value
                return []
            else:
                print(f"âš ï¸  StructurÄƒ JSON neaÈ™teptatÄƒ Ã®n {json_path}")
                return []
    except json.JSONDecodeError as e:
        print(f"âŒ Eroare la parsarea JSON: {e}")
        return []

def extract_key_from_url(url):
    """
    Extrage cheia din URL pentru matching
    Exemplu: https://adt.arcanum.com/ro/view/Energetica_1969 -> Energetica_1969
    """
    if not isinstance(url, str):
        return None
    match = re.search(r'/view/([^/?]+)', url)
    if match:
        return match.group(1)
    return None

def extract_key_from_folder(folder_name):
    """
    Extrage cheia din numele folderului pentru matching
    Exemplu: "Energetica, 1969 (Anul 17, nr. 2-8)" -> Energetica_1969
    """
    match = re.search(r'^([^,]+),\s*(\d{4})', folder_name)
    if match:
        name = match.group(1).strip()
        year = match.group(2)
        # EliminÄƒ spaÈ›iile È™i diacriticele pentru matching
        name_clean = name.replace(' ', '').replace('È™', 's').replace('È˜', 'S').replace('È›', 't').replace('Èš', 'T')
        key = f"{name_clean}_{year}"
        return key
    return None

def extract_key_from_filename(filename):
    """
    Extrage cheia din numele fiÈ™ierului PDF
    Exemplu: "StiintaSiTehnica_1964-1627417979__pages400-449.pdf" -> StiintaSiTehnica_1964
    """
    match = re.search(r'^([^_]+_\d{4})', filename)
    if match:
        return match.group(1)
    return None

def extract_page_range_from_filename(filename):
    """Extrage intervalul de pagini din numele fiÈ™ierului"""
    match = re.search(r'__pages(\d+)-(\d+)\.pdf$', filename)
    if match:
        start_page = int(match.group(1))
        end_page = int(match.group(2))
        return (start_page, end_page)
    return None

def scan_root_pdfs(root_drive):
    """
    ScaneazÄƒ fiÈ™ierele PDF din root-ul drive-ului È™i le grupeazÄƒ dupÄƒ cheie
    Returns: dict with key -> list of (start, end, filepath)
    """
    root_pdfs = defaultdict(list)

    if not os.path.exists(root_drive):
        print(f"âš ï¸  Drive-ul {root_drive} nu existÄƒ!")
        return root_pdfs

    try:
        files = os.listdir(root_drive)
        for filename in files:
            if filename.endswith('.pdf') and '__pages' in filename:
                filepath = os.path.join(root_drive, filename)
                key = extract_key_from_filename(filename)
                page_range = extract_page_range_from_filename(filename)

                if key and page_range:
                    root_pdfs[key].append((page_range[0], page_range[1], filepath))
    except Exception as e:
        print(f"âš ï¸  Eroare la scanarea root-ului: {e}")

    return root_pdfs

def calculate_segment_size(pdf_segments):
    """CalculeazÄƒ dimensiunea standard a unui segment bazat pe PDF-urile existente"""
    if not pdf_segments:
        return 49  # Default

    sizes = [end - start + 1 for start, end, *_ in pdf_segments]

    if sizes:
        return max(set(sizes), key=sizes.count)
    return 49

def split_gap_into_segments(gap_start, gap_end, segment_size):
    """Ãmparte o gaurÄƒ mare Ã®n segmente mai mici"""
    segments = []
    current = gap_start

    while current <= gap_end:
        segment_end = min(current + segment_size - 1, gap_end)
        segments.append((current, segment_end))
        current = segment_end + 1

    return segments

def find_all_gaps(base_directory, state_json_path, root_drive):
    """GÄƒseÈ™te toate gÄƒurile din secvenÈ›ele PDF, verificÃ¢nd atÃ¢t Temporare cÃ¢t È™i root-ul drive-ului"""

    # ÃncarcÄƒ state.json
    state_data = load_state_json(state_json_path)

    if not state_data:
        print("âš ï¸  Nu s-au putut Ã®ncÄƒrca date din state.json")
        return

    # CreeazÄƒ un dicÈ›ionar pentru matching rapid
    state_dict = {}
    for entry in state_data:
        if not isinstance(entry, dict):
            continue

        url = entry.get('url')
        if not url:
            continue

        key = extract_key_from_url(url)
        if key:
            state_dict[key] = {
                'total_pages': entry.get('total_pages', entry.get('pages', 0)),
                'title': entry.get('title', 'Unknown'),
                'last_successful_segment_end': entry.get('last_successful_segment_end', 0),
                'completed_at': entry.get('completed_at', '')
            }

    print(f"âœ… ÃncÄƒrcat state.json cu {len(state_dict)} intrÄƒri\n")

    # ScaneazÄƒ PDF-urile din root
    print(f"ğŸ” Scanare PDF-uri din {root_drive}...")
    root_pdfs = scan_root_pdfs(root_drive)
    if root_pdfs:
        print(f"âœ… GÄƒsite {sum(len(v) for v in root_pdfs.values())} PDF-uri Ã®n root\n")
    else:
        print(f"â„¹ï¸  Nu s-au gÄƒsit PDF-uri Ã®n root\n")

    # Parcurge toate subfolderele din Temporare
    folders_data = {}
    for root, dirs, files in os.walk(base_directory):
        if root == base_directory:
            continue

        folder_name = os.path.basename(root)
        folder_key = extract_key_from_folder(folder_name)

        if not folder_key:
            continue

        # GÄƒseÈ™te toate fiÈ™ierele PDF cu pattern-ul __pages din folder
        pdf_segments = []
        for filename in files:
            if filename.endswith('.pdf') and '__pages' in filename:
                page_range = extract_page_range_from_filename(filename)
                if page_range:
                    filepath = os.path.join(root, filename)
                    pdf_segments.append((page_range[0], page_range[1], filepath))

        folders_data[folder_key] = {
            'folder_name': folder_name,
            'folder_path': root,
            'segments': pdf_segments
        }

    # ProceseazÄƒ fiecare folder È™i combinÄƒ cu PDF-urile din root
    all_keys = set(folders_data.keys()) | set(root_pdfs.keys())

    for key in sorted(all_keys):
        folder_info = folders_data.get(key, {})
        folder_name = folder_info.get('folder_name', f'[Folder lipsÄƒ pentru {key}]')
        folder_path = folder_info.get('folder_path', '')
        folder_segments = folder_info.get('segments', [])

        # CombinÄƒ segmentele din folder È™i din root
        root_segments = root_pdfs.get(key, [])
        all_segments = folder_segments + root_segments

        if not all_segments:
            continue

        # GÄƒseÈ™te informaÈ›iile despre total_pages din state.json
        state_info = state_dict.get(key, {})
        total_pages = state_info.get('total_pages', 0)
        last_successful = state_info.get('last_successful_segment_end', 0)
        completed_at = state_info.get('completed_at', '')
        is_incomplete = (not completed_at or completed_at == "")

        # SorteazÄƒ segmentele dupÄƒ pagina de Ã®nceput È™i eliminÄƒ duplicatele
        all_segments.sort(key=lambda x: x[0])

        # EliminÄƒ duplicate (acelaÈ™i interval de pagini)
        unique_segments = []
        seen_ranges = set()
        for start, end, filepath in all_segments:
            range_key = (start, end)
            if range_key not in seen_ranges:
                unique_segments.append((start, end, filepath))
                seen_ranges.add(range_key)

        # CalculeazÄƒ dimensiunea standard a segmentelor
        segment_size = calculate_segment_size(unique_segments)

        # VerificÄƒ gÄƒurile Ã®n secvenÈ›Äƒ
        gaps = []

        # IMPORTANT: VerificÄƒ dacÄƒ lipsesc segmente de la Ã®nceput (de la 1 pÃ¢nÄƒ la primul segment)
        first_segment_start = unique_segments[0][0]
        if first_segment_start > 1:
            gaps.append((1, first_segment_start - 1))

        # VerificÄƒ gÄƒurile Ã®ntre segmente
        for i in range(len(unique_segments) - 1):
            current_end = unique_segments[i][1]
            next_start = unique_segments[i + 1][0]

            if next_start > current_end + 1:
                gaps.append((current_end + 1, next_start - 1))

        # VerificÄƒ dacÄƒ lipsesc PDF-uri de la final
        last_segment_end = unique_segments[-1][1]

        if total_pages and total_pages > last_segment_end:
            gaps.append((last_segment_end + 1, total_pages))

        # AfiÈ™eazÄƒ doar dacÄƒ sunt probleme
        if gaps or root_segments:
            print(f"{'='*80}")
            print(f"ğŸ“ {folder_name}")
            print(f"ğŸ”‘ Key: {key}")

            if total_pages:
                print(f"ğŸ“„ Total pagini (din state.json): {total_pages}")
            else:
                print(f"âš ï¸  Total pagini: NECUNOSCUT")

            if is_incomplete:
                print(f"âš ï¸  ColecÈ›ie INCOMPLETÄ‚ (completed_at este gol)")
                if last_successful:
                    print(f"   Ultimul segment cu succes: {last_successful}")

            print(f"ğŸ“Š Segmente gÄƒsite:")
            print(f"   - Ãn folder Temporare: {len(folder_segments)}")
            print(f"   - Ãn root (G:\\): {len(root_segments)}")
            print(f"   - Total unice: {len(unique_segments)}")

            if unique_segments:
                print(f"   Primul segment: pages {unique_segments[0][0]}-{unique_segments[0][1]}")
                print(f"   Ultimul segment: pages {unique_segments[-1][0]}-{last_segment_end}")

            print(f"   Dimensiune segment standard: {segment_size} pagini")
            print(f"{'='*80}")

            # AfiÈ™eazÄƒ PDF-urile din root care trebuie mutate
            if root_segments:
                print(f"\nğŸ“¦ PDF-uri Ã®n root care ar trebui mutate Ã®n folder:")
                for start, end, filepath in root_segments:
                    filename = os.path.basename(filepath)
                    in_folder = any(s[0] == start and s[1] == end for s in folder_segments)
                    status = "âœ“ (existÄƒ deja Ã®n folder)" if in_folder else "âš ï¸  (lipseÈ™te din folder)"
                    print(f"   {status} {filename}")
                    print(f"      De la: {filepath}")
                    if folder_path:
                        print(f"      CÄƒtre: {os.path.join(folder_path, filename)}")
                print()

            # Ãmparte fiecare gaurÄƒ Ã®n segmente È™i afiÈ™eazÄƒ
            if gaps:
                print(f"âŒ GÄ‚URI Ã®n secvenÈ›Äƒ:")
                for gap_start, gap_end in gaps:
                    gap_segments = split_gap_into_segments(gap_start, gap_end, segment_size)
                    for seg_start, seg_end in gap_segments:
                        print(f"   âŒ LipseÈ™te: pages {seg_start}-{seg_end}")
                print()

def main():
    # Directoarele
    base_dir = r"g:\Temporare"
    state_json = r"g:\state.json"
    root_drive = r"g:\\"

    if not os.path.exists(base_dir):
        print(f"âŒ Directorul {base_dir} nu existÄƒ!")
        return

    if not os.path.exists(state_json):
        print(f"âŒ FiÈ™ierul {state_json} nu existÄƒ!")
        return

    print("ğŸ” Verificare PDF-uri lipsÄƒ Ã®n colecÈ›ii...\n")
    find_all_gaps(base_dir, state_json, root_drive)
    print("âœ… Verificare finalizatÄƒ!")

if __name__ == "__main__":
    main()